---
marp: true
theme: default
paginate: true
---

<!-- _class: lead -->
<!-- _paginate: false -->

# Predi√ß√£o de Sucesso Eleitoral
## Deputados Federais no Brasil

**Valida√ß√£o Temporal: 2018 ‚Üí 2022**

Artur Garcia & Artur Saraiva
Universidade Federal do Cear√° (UFC)
Disciplina: Aprendizagem de M√°quina
Janeiro/2026

<!--
NOTAS DO APRESENTADOR (Slide 1 - Abertura):
- Cumprimentar a banca/audi√™ncia
- Apresentar-se brevemente
- Contextualizar: "Nosso trabalho investiga se √© poss√≠vel prever quais candidatos a deputado federal ser√£o eleitos usando apenas dados declarat√≥rios dispon√≠veis antes da elei√ß√£o"
- Enfatizar a valida√ß√£o temporal (treino 2018, teste 2022) como diferencial metodol√≥gico
- Tempo: ~1 minuto
-->

---

# Contexto e Motiva√ß√£o

## Por que prever sucesso eleitoral?

- **Democracia brasileira**: Sistema proporcional com lista aberta
- **Cen√°rio desafiador**: Milhares de candidatos, poucos eleitos
- **Quest√£o central**: Fatores estruturais determinam vit√≥ria?

## Aplica√ß√µes pr√°ticas

‚úÖ Partidos pol√≠ticos otimizarem aloca√ß√£o de recursos
‚úÖ Consultorias eleitorais orientarem candidatos
‚úÖ Cidad√£os compreenderem din√¢micas de poder

<!--
NOTAS DO APRESENTADOR (Slide 2 - Contexto):
- Explicar o sistema eleitoral brasileiro: "No Brasil, deputados federais s√£o eleitos por sistema proporcional de lista aberta - o eleitor vota em um candidato espec√≠fico, mas a distribui√ß√£o de vagas considera o desempenho do partido/coliga√ß√£o"
- Destacar a complexidade: "Em 2022, foram quase 10.000 candidatos para 513 vagas - taxa de sucesso de cerca de 5%"
- Mencionar desbalanceamento como desafio central
- Conectar com slide seguinte: "Mas antes de entrar na metodologia, vamos definir claramente o problema"
- Tempo: ~1,5 minuto
-->

---

# Defini√ß√£o do Problema

## Tipo de problema: 
**Classifica√ß√£o bin√°ria supervisionada**

## Vari√°vel alvo (Target)
```
ELEITO = {
  1: Candidato eleito (inclui "ELEITO POR M√âDIA" e "ELEITO POR QP")
  0: Candidato n√£o eleito
}
```
---
## Desafio principal
**Desbalanceamento extremo**: ~90% n√£o-eleitos vs. ~10% eleitos
- Raz√£o de desbalanceamento geral: **1:~15**
- Implica em uso de m√©tricas robustas (F1-Score, AUC-PR, ...)
- Modelo tende a favorecer classe majorit√°ria

---

![width=1000px](../../figures/desbalanceamento.png)

<!--
NOTAS DO APRESENTADOR (Slide 3 - Defini√ß√£o do Problema):
- Enfatizar que √© classifica√ß√£o bin√°ria: "Queremos prever se um candidato ser√° eleito ou n√£o"
- Explicar as categorias inclu√≠das: "Consideramos eleitos tanto os que atingiram o quociente eleitoral quanto os eleitos por m√©dia do partido"
- IMPORTANTE: Destacar o desbalanceamento e suas implica√ß√µes: "Este √© o maior desafio do projeto. Com apenas 10% de positivos, um modelo trivial que sempre prediz 'n√£o-eleito' teria 90% de acur√°cia, mas seria in√∫til"
- Conectar com m√©tricas: "Por isso, n√£o podemos usar acur√°cia simples - precisamos de F1, que equilibra precis√£o e recall"
- Tempo: ~1,5 minuto
-->

<!--
NOTAS DO APRESENTADOR (Slide 6 - EDA Desbalanceamento):
[NOTA: Este slide assume que voc√™ tem uma figura salva. Se n√£o tiver, use os gr√°ficos gerados no notebook]

- Mostrar o gr√°fico e explicar: "Vejam claramente a despropor√ß√£o entre eleitos (verde) e n√£o-eleitos (vermelho)"
- Quantificar: "Para cada candidato eleito, temos aproximadamente 9 que n√£o se elegem"
- Explicar impacto: "Isso significa que o modelo pode ter uma tend√™ncia natural a prever 'n√£o-eleito' com mais frequ√™ncia"
- Conectar com estrat√©gia: "Para compensar, usamos class weights (pesos de classe) no treinamento - penalizamos mais erros na classe minorit√°ria"
- Mencionar m√©tricas: "E por isso escolhemos m√©tricas que n√£o s√£o enganadas pelo desbalanceamento, como F1 e AUC-PR"
- Tempo: ~1,5 minuto
-->

---

# Dados e Pr√©-processamento

## Fonte dos dados
**Tribunal Superior Eleitoral (TSE)** - Dados p√∫blicos

| Dataset | 2018 | 2022 |
|---------|------|------|
| Candidatos | ~8.000 | ~10.000 |
| Features originais | 50+ | 50+ |
| Taxa de eleitos | 6.7% | 5.4% |

---

## Bases integradas
1. **Consulta de Candidatos**: Dados demogr√°ficos e pol√≠ticos
2. **Complementar**: Idade, reelei√ß√£o, despesa m√°xima
3. **Bens**: Patrim√¥nio declarado

<!--
NOTAS DO APRESENTADOR (Slide 4 - Dados):
- Explicar origem dos dados: "Utilizamos dados abertos do TSE, que disponibiliza informa√ß√µes declarat√≥rias de todos os candidatos"
- Detalhar processo de integra√ß√£o: "Unimos tr√™s bases diferentes usando o c√≥digo √∫nico do candidato (SQ_CANDIDATO)"
- Destacar tamanho dos datasets: "Trabalhamos com aproximadamente 8 mil candidatos em 2018 e 10 mil em 2022, ap√≥s filtros de qualidade"
- Mencionar a taxa de eleitos: "Veja que a taxa de elei√ß√£o √© bastante est√°vel entre os ciclos, em torno de 6%"
- Transi√ß√£o: "Mas esses dados brutos n√£o estavam prontos para uso - precisamos de limpeza e tratamento"
- Tempo: ~1,5 minuto
-->

---

# ETL - Pipeline de Limpeza

## Principais transforma√ß√µes

1. **Defini√ß√£o do target**: Mapeamento de situa√ß√µes eleitorais
2. **Filtros de qualidade**:
   - Remover candidatos com situa√ß√£o irregular (CD_SITUACAO_CANDIDATURA ‚â† 12)
3. **Tratamento de missings**
4. **Harmoniza√ß√£o de partidos**: Fus√µes entre 2018-2022
   - `PR` ‚Üí `PL`, `DEM` ‚Üí `UNI√ÉO`, etc.

**Resultado**: Dataset limpo e consistente para modelagem

<!--
NOTAS DO APRESENTADOR (Slide 5 - ETL):
- Explicar necessidade de limpeza: "Dados do TSE cont√™m c√≥digos especiais (#NULO, #NE) e inconsist√™ncias que precisam ser tratadas"
- Detalhar estrat√©gia de imputa√ß√£o: "Para valores faltantes, usamos estrat√©gias conservadoras: candidatos sem informa√ß√£o de reelei√ß√£o s√£o assumidos como primeira candidatura"
- IMPORTANTE: Explicar fus√£o de partidos: "Entre 2018 e 2022 houve fus√µes partid√°rias. Por exemplo, PR virou PL, DEM se fundiu √† UNI√ÉO. Precisamos harmonizar isso para o modelo entender que s√£o o mesmo partido"
- Valida√ß√£o: "Todos os passos foram validados com logging detalhado para garantir integridade dos dados"
- Transi√ß√£o: "Com dados limpos, podemos agora explorar os padr√µes"
- Tempo: ~1,5 minuto
-->

---

# EDA - Correla√ß√µes Entre Features

---

## Matriz de correla√ß√£o (vari√°veis num√©ricas)

![width:900px](../../figures/correlation_matrix_numeric_variables.png)

---

## üí° Insights
- **Correla√ß√µes fracas** (<0.3): Nenhuma feature sozinha determina vit√≥ria
- **Intera√ß√µes complexas**: Modelos ensemble necess√°rios

<!--
NOTAS DO APRESENTADOR (Slide 7 - Correla√ß√µes):
- Interpretar a matriz: "Vemos que todas as correla√ß√µes com ELEITO s√£o fracas, abaixo de 0.15"
- Destacar o maior valor: "A correla√ß√£o mais forte √© com Despesa M√°xima (0.122), sugerindo que candidatos com tetos maiores t√™m ligeira vantagem"
- IMPORTANTE: Explicar implica√ß√£o: "Isso √© bom e ruim. Bom porque n√£o h√° uma feature dominante que tornaria o problema trivial. Ruim porque precisaremos capturar intera√ß√µes complexas entre m√∫ltiplas vari√°veis"
- Conectar com modelos: "√â por isso que modelos ensemble como Random Forest e XGBoost tendem a funcionar melhor - eles capturam essas intera√ß√µes n√£o-lineares"
- Mencionar patrim√¥nio: "Vejam que patrim√¥nio tem correla√ß√£o bem fraca (0.081) - ser rico n√£o garante elei√ß√£o, mas ajuda indiretamente"
- Tempo: ~1,5 minuto
-->

---

# EDA - Histogramas de Distribui√ß√µes
---
![width:1000px](../../figures/histograms_numeric_variables.png)

---

# EDA - Testes de Signific√¢ncia

## Mann-Whitney U Test (n√£o-param√©trico)

| Feature | Eleitos (m√©dia) | N√£o-eleitos (m√©dia) | p-value | Signific√¢ncia |
|---------|----------------|---------------------|---------|---------------|
| **Patrim√¥nio** | R$ 2.5M | R$ 821K | p < 0.001 | ‚úÖ Alta |
| **Idade** | 49.5 anos | 48.55 anos | p < 0.05 | ‚úÖ Moderada |

## Interpreta√ß√£o
- Diferen√ßas s√£o **estatisticamente significativas**
- Eleitos t√™m, em m√©dia, **90% mais patrim√¥nio**

<!--
NOTAS DO APRESENTADOR (Slide 8 - Testes de Signific√¢ncia):
- Explicar o teste: "Usamos Mann-Whitney U, um teste n√£o-param√©trico robusto a outliers, para verificar se eleitos e n√£o-eleitos s√£o estatisticamente diferentes nestas vari√°veis"
- Interpretar p-values: "p < 0.001 significa que a chance dessas diferen√ßas serem aleat√≥rias √© menor que 0.1% - muito improv√°vel"
- Destacar magnitudes: "Eleitos t√™m quase o dobro de patrim√¥nio - diferen√ßas substanciais"
- IMPORTANTE: Fazer distin√ß√£o entre correla√ß√£o e causalidade: "Aten√ß√£o: isso n√£o prova que patrim√¥nio causa vit√≥ria - apenas que est√£o associados. Pode haver vari√°veis confundidoras, como capital pol√≠tico ou notoriedade"
- Mencionar idade: "Idade tem efeito pequeno mas significativo - candidatos eleitos tendem a ser um pouco mais velhos"
- Transi√ß√£o: "Al√©m das vari√°veis num√©ricas, categorias como partido tamb√©m importam muito"
- Tempo: ~2 minutos
-->

---

# EDA - Partidos e Ocupa√ß√µes

---
![width:1000px](../../figures/party_occupation_success_rates.png)

<!--
NOTAS DO APRESENTADOR (Slide 9 - Partidos e Ocupa√ß√µes):
- Interpretar partidos: "Vemos clara vantagem dos partidos grandes - PL e PT t√™m taxas de sucesso 2x maiores que a m√©dia nacional (10%)"
- Explicar mecanismos: "Isso reflete vantagens estruturais: mais tempo de TV, melhor infraestrutura de campanha, coliga√ß√µes fortes, e recursos financeiros"
- CRUCIAL: Destacar incumb√™ncia: "Vejam o efeito dram√°tico da incumb√™ncia - deputados que buscam reelei√ß√£o t√™m taxa de sucesso acima de 50%! √â o preditor mais forte"
- Interpretar ocupa√ß√µes: "Profiss√µes liberais de prest√≠gio (advogado, m√©dico) e empres√°rios t√™m vantagem - capital social, recursos e redes de contato"
- Conectar com features: "Por isso criamos a feature IS_REELEICAO - ela captura esse padr√£o fort√≠ssimo"
- Mencionar encoding: "Essas categorias ser√£o transformadas em target encoding no pipeline de features"
- Tempo: ~2 minutos
-->

---

# Baseline Models - Sanity Check

## Objetivo
Estabelecer **patamar m√≠nimo** antes de modelos complexos

## Resultados (Valida√ß√£o 2018 ‚Üí 2022)

| Modelo | F1-Score | AUC-ROC | AUC-PR | Balanced Acc |
|--------|----------|---------|--------|--------------|
| **Most Frequent** | 0.0000 | 0.5000 | 0.0540 | 0.5000 |
| **Stratified** | 0.0631 | 0.5021 | 0.0543 | 0.5021 |
| **Logistic (default)** | 0.0000 | 0.5323 | 0.0694 | 0.5000 |

<!--
NOTAS DO APRESENTADOR (Slide 10 - Baselines):
- Explicar prop√≥sito: "Antes de partir para modelos complexos, estabelecemos baselines simples. S√£o 'controles de sanidade' - qualquer modelo sofisticado DEVE super√°-los significativamente"
- Interpretar Most Frequent: "Modelo que sempre prediz classe majorit√°ria (n√£o-eleito) - acur√°cia de 90% mas F1 zero, completamente in√∫til"
- Explicar Stratified: "Prediz aleatoriamente respeitando propor√ß√µes das classes - gera AUC de 0.5, equivalente a um chute"
- IMPORTANTE: Destacar Logistic Regression: "Regress√£o log√≠stica simples (apenas idade e patrim√¥nio, sem feature engineering) j√° atinge F1 de 0.0000 e AUC de 0.5323 - √© um baseline respeit√°vel"
- Estabelecer meta: "Nosso objetivo √© superar substancialmente este resultado com engenharia de features e modelos ensemble"
- Transi√ß√£o: "E para isso, precisamos transformar os dados brutos em features informativas"
- Tempo: ~2 minutos
-->

---

# Feature Engineering - Estrat√©gia

## 1. Features Bin√°rias
- `IS_REELEICAO`: Candidato busca reelei√ß√£o (S/N)
- `IS_FEMININO`: G√™nero feminino
- `IS_PARTIDO_GRANDE`: Partido top-6
- `TEM_BENS`: Possui bens declarados

---

## 2. Transforma√ß√µes Logar√≠tmicas
- `LOG_BENS = log(TOTAL_BENS + 1)`
- `LOG_DESPESA_MAX = log(VR_DESPESA_MAX + 1)`

## 3. Features de Coliga√ß√£o
- `QTD_PARTIDOS_COLIG`: Tamanho da coliga√ß√£o
- `IS_COLIGADO`: Pertence a coliga√ß√£o (vs. partido isolado)

<!--
NOTAS DO APRESENTADOR (Slide 11 - Feature Engineering Parte 1):
- Explicar filosofia: "Feature engineering √© o processo de transformar dados brutos em representa√ß√µes que o modelo consiga aprender melhor"
- Detalhar bin√°rias: "Criamos indicadores 0/1 para capturar presen√ßa/aus√™ncia de caracter√≠sticas importantes"
- IMPORTANTE: Justificar transforma√ß√£o log: "Patrim√¥nio e despesa t√™m distribui√ß√µes extremamente assim√©tricas (alguns candidatos com valores muito altos). A transforma√ß√£o log comprime outliers e torna a distribui√ß√£o mais normal"
- Explicar coliga√ß√µes: "Quantificamos for√ßa das alian√ßas - coliga√ß√µes maiores t√™m mais candidatos e mais chances de atingir quociente eleitoral"
- Mencionar IS_PARTIDO_GRANDE: "Criamos esta feature ap√≥s an√°lise explorat√≥ria mostrar vantagem clara dos 6 maiores partidos"
- Tempo: ~1,5 minuto
-->

---

# Feature Engineering - Target Encoding

## Target Encoding com Smoothing Bayesiano

Para cada categoria (partido, ocupa√ß√£o, UF, etc.):

$$
\text{encoded\_value} = \frac{n_{categoria} \times \bar{y}_{categoria} + \alpha \times \bar{y}_{global}}{n_{categoria} + \alpha}
$$

- **Œ± = 10** (par√¢metro de smoothing validado)
- **Previne overfitting** em categorias com poucas observa√ß√µes
- **Preserva sinal** em categorias frequentes

<!--
NOTAS DO APRESENTADOR (Slide 12 - Target Encoding):
- Explicar problema: "Categorias como partido t√™m 30+ valores distintos - one-hot encoding criaria muitas features esparsas e causaria overfitting"
- Introduzir target encoding: "Substitu√≠mos cada categoria pela taxa m√©dia de sucesso (elei√ß√£o) daquela categoria"
- CRUCIAL: Explicar smoothing: "Mas h√° um problema - partidos pequenos com poucos candidatos teriam estimativas inst√°veis. Por exemplo, se um partido tem 2 candidatos e 1 foi eleito, a taxa seria 50%, mas n√£o √© confi√°vel"
- Mostrar f√≥rmula: "O smoothing bayesiano resolve isso combinando a taxa observada com a taxa global, dando mais peso √† global quando h√° poucos dados"
- Explicar alfa: "Œ±=10 foi escolhido por valida√ß√£o cruzada - balanceia vi√©s e vari√¢ncia. Alfa alto confia mais na m√©dia global (underfitting), alfa baixo confia mais nos dados (overfitting)"
- Mencionar vazamento: "IMPORTANTE: Encodings s√£o calculados APENAS no treino e aplicados no teste - evita data leakage"
- Tempo: ~2,5 minutos
-->

---

# Metodologia - Valida√ß√£o Temporal

## Setup Experimental

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   TREINO: 2018  ‚îÇ  ‚îÄ‚îÄ‚îÄ> ‚îÇ   TESTE: 2022   ‚îÇ
‚îÇ   (~8K cands)   ‚îÇ       ‚îÇ   (~10K cands)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```
---
## Por que valida√ß√£o temporal?

‚úÖ **Simula cen√°rio real**: Prever elei√ß√£o futura com dados passados
‚úÖ **Mais rigoroso**: N√£o pode "espiar" dados de teste durante treino
‚úÖ **Detecta concept drift**: Mudan√ßas em padr√µes eleitorais

## Limita√ß√£o
Apenas 2 ciclos dispon√≠veis - impossibilita an√°lise de tend√™ncias

<!--
NOTAS DO APRESENTADOR (Slide 13 - Valida√ß√£o Temporal):
- CRUCIAL: Explicar diferen√ßa: "Valida√ß√£o temporal √© muito mais rigorosa que valida√ß√£o cruzada. Em CV, embaralhamos dados de todos os anos - o modelo 'v√™' exemplos de 2022 durante treino, mesmo que indiretamente"
- Justificar escolha: "Aqui, treinamos APENAS com 2018 completo e testamos APENAS em 2022. Isso replica o cen√°rio real: usar elei√ß√µes passadas para prever a pr√≥xima"
- Mencionar concept drift: "Esta estrat√©gia revela se padr√µes eleitorais mudaram entre ciclos. Por exemplo, se novos partidos emergiram ou se redes sociais alteraram a din√¢mica"
- Destacar limita√ß√£o: "Idealmente ter√≠amos mais ciclos (2014, 2010...) para estimar taxa de degrada√ß√£o temporal, mas TSE padronizou dados apenas a partir de 2018"
- Conectar com resultados: "O fato de nosso modelo generalizar bem entre 2018 e 2022 (gap de 4 anos) √© evid√™ncia de robustez"
- Transi√ß√£o: "Agora vamos √† estrat√©gia de modelagem"
- Tempo: ~2 minutos
-->

---

# Estrat√©gia de Modelagem - 3 Etapas

## Etapa 1: Screening (Grid Reduzido)
- **4 modelos**: Logistic Regression, Random Forest, Gradient Boosting, XGBoost
- **Objetivo**: Identificar arquiteturas promissoras

## Etapa 2: Sele√ß√£o de Finalistas 
- Selecionar **Top 2** por F1-Score no teste

## Etapa 3: Otimiza√ß√£o Completa
- **Grid expandido** com RandomizedSearchCV para espa√ßos grandes
- **M√©trica de sele√ß√£o**: F1-Score (5-fold CV estratificado)

<!--
NOTAS DO APRESENTADOR (Slide 14 - Estrat√©gia de Modelagem):
- Explicar motiva√ß√£o: "Testar grid completo em todos os modelos seria computacionalmente invi√°vel - estamos falando de milhares de combina√ß√µes"
- Detalhar etapa 1: "Fazemos um screening inicial com hiperpar√¢metros limitados - o suficiente para identificar quais arquiteturas se adaptam melhor ao problema"
- Justificar Top 2: "Selecionamos apenas os 2 melhores para otimiza√ß√£o final - concentramos recursos onde h√° mais potencial"
- IMPORTANTE: Explicar RandomizedSearchCV: "Para grids muito grandes (>100 combina√ß√µes), usamos amostragem aleat√≥ria ao inv√©s de busca exaustiva - 50 itera√ß√µes geralmente encontram √≥timo pr√≥ximo do melhor global"
- Mencionar class weights: "Em todos os modelos, usamos class_weight='balanced' ou scale_pos_weight para compensar desbalanceamento"
- Destacar CV estratificado: "Valida√ß√£o cruzada preserva propor√ß√£o de classes em cada fold - cr√≠tico para dados desbalanceados"
- Tempo: ~2 minutos
-->

---

# Tratamento do Desbalanceamento

## Estrat√©gias aplicadas

### Durante Treinamento
- **Class Weights**: Penaliza√ß√£o de erros na classe minorit√°ria
  - Ratio: **~14x mais peso para eleitos**

### Durante Avalia√ß√£o
- **M√©tricas apropriadas**:
  - ‚ùå Acur√°cia
  - ‚úÖ F1-Score, AUC-ROC, AUC-PR

<!--
NOTAS DO APRESENTADOR (Slide 15 - Desbalanceamento):
- Refor√ßar o problema: "Com 9:1 de desbalanceamento, um modelo ing√™nuo que sempre prediz 'n√£o-eleito' teria 90% de acur√°cia mas seria completamente in√∫til"
- Explicar class weights: "Calculamos pesos automaticamente com sklearn - eleitos recebem peso 14x maior. Isso faz com que errar na classe minorit√°ria 'doa' mais na fun√ß√£o de perda"
- IMPORTANTE: Justificar escolha de m√©tricas: "F1 √© perfeito porque combina precision (dos que predizemos eleitos, quantos realmente foram?) com recall (dos eleitos reais, quantos capturamos?)"
- Explicar AUC-PR: "AUC-PR √© especialmente √∫til em desbalanceamento - mostra performance focando na classe rara. Um modelo ruim tem AUC-PR pr√≥ximo da preval√™ncia (10%), bom > 30%"
- Mencionar SMOTE: "Testamos SMOTE (synthetic oversampling) mas n√£o melhorou performance - class weights foram suficientes"
- Transi√ß√£o: "Vejamos agora os resultados dessa estrat√©gia"
- Tempo: ~2 minutos
-->

---

# Resultados - Screening (Etapa 1)

## Grid Reduzido (2018 ‚Üí 2022)

| Modelo | F1-Score | AUC-ROC | AUC-PR | Precision | Recall |
|--------|----------|---------|--------|-----------|--------|
| **Random Forest** | **0.5992** | **0.9312** | **0.5568** | 0.6360 | 0.5664 |
| **XGBoost** | 0.5833 | 0.9085 | 0.4957 | 0.5513 | 0.6191 |
| **Gradient Boosting** | 0.5720 | 0.9267 | 0.5403 | 0.6423 | 0.5156 |
| **Logistic Regression** | 0.4491 | 0.9340 | 0.5517 | 0.3106 | 0.8105 |

<!--
## üí° Insights
- **Random Forest** domina em F1 e demonstra excelente capacidade de generaliza√ß√£o
- RF e XGBoost selecionados como **finalistas** para otimiza√ß√£o completa

NOTAS DO APRESENTADOR (Slide 16 - Resultados Screening):
- Interpretar resultados: "Vejam que Random Forest domina com F1 de 0.60 - performance excelente! AUC-ROC de 0.93 √© not√°vel"
- Contextualizar performance: "F1 de 0.60 √© um resultado muito bom considerando o desbalanceamento. Superamos amplamente os baselines!"
- IMPORTANTE: Explicar por que ensemble vence: "Modelos baseados em √°rvores (Random Forest, XGBoost) capturam intera√ß√µes n√£o-lineares e s√£o naturalmente robustos a outliers - patrim√¥nio e despesa t√™m distribui√ß√µes muito assim√©tricas"
- Destacar AUC-ROC: "AUC acima de 0.90 √© excepcional! Significa que o modelo ranqueia corretamente candidatos eleitos vs n√£o-eleitos em mais de 90% dos casos - discrimina√ß√£o excelente"
- Mencionar AUC-PR: "AUC-PR de 0.56 (Random Forest) √© 10x maior que baseline aleat√≥rio (0.054 = preval√™ncia) - ganho extraordin√°rio"
- Destacar Logistic Regression: "Note que Logistic Regression tem recall alt√≠ssimo (0.81) mas precision baixa (0.31) - prediz muitos eleitos, captura bem a classe positiva mas com muitos falsos positivos"
- Anunciar finalistas: "Com base nestes resultados, selecionamos Random Forest e XGBoost para otimiza√ß√£o completa"
- Tempo: ~2 minutos
-->


---

# Resultados Finais - Otimiza√ß√£o Completa

## Grid Completo (Finalistas)

| Modelo | F1-Score | AUC-ROC | AUC-PR | Precision | Recall |
|--------|----------|---------|--------|-----------|--------|
| **Random Forest** | **0.6117** | **0.9324** | **0.5605** | 0.6471 | 0.5801 |
| **XGBoost** | 0.5768 | 0.9224 | 0.5267 | 0.5097 | 0.6641 |

## üèÜ Modelo Vencedor: **Random Forest**

---

![](../../figures/confusion_matrix_finalistas.png)


<!--
### Hiperpar√¢metros otimizados
- `n_estimators`: 300
- `max_depth`: 20
- `min_samples_split`: 2
- `min_samples_leaf`: 1
- `class_weight`: balanced

NOTAS DO APRESENTADOR (Slide 17 - Resultados Finais):
- Anunciar vencedor: "Ap√≥s otimiza√ß√£o completa, Random Forest mant√©m a lideran√ßa com F1 de 0.6117"
- Destacar melhoria: "Comparado com o screening, ganhamos 0.0125 pontos em F1 (2.1% de melhoria relativa) - a otimiza√ß√£o valeu a pena"
- Explicar hiperpar√¢metros: "Modelo final usa 300 √°rvores com profundidade 20 - mais complexidade que no screening inicial, mas com controle via min_samples para prevenir overfitting"
- Contextualizar performance absoluta: "F1 de 0.61 em problema t√£o desbalanceado √© excelente - supera amplamente baselines e reflete que o modelo capturou bem os padr√µes eleitorais"
- IMPORTANTE: Mencionar precision vs recall: "Random Forest tem melhor equil√≠brio (precision=0.65, recall=0.58), enquanto XGBoost sacrifica precision por recall mais alto (0.51 vs 0.66)"
- Comparar com XGBoost: "XGBoost ficou com F1=0.58 - diferen√ßa de 3.5 pontos. Ambos t√™m AUC-ROC > 0.92, mostrando excelente capacidade discriminativa"
- Destacar AUC: "AUC-ROC de 0.93 √© excepcional - modelo ranqueia corretamente 93% das vezes!"
- Transi√ß√£o: "Vamos agora visualizar a performance deste modelo"
- Tempo: ~2,5 minutos
-->

---

# Curvas ROC e Precision-Recall

![width:900px](../../figures/roc_pr_curves.png)

<!--
## Interpreta√ß√£o
- **ROC (esquerda)**: Discrimina√ß√£o geral - AUC 0.93 (excelente)
- **PR (direita)**: Performance na classe positiva - AUC 0.56
- **Banda de confian√ßa**: Bootstrap 100x mostra robustez

NOTAS DO APRESENTADOR (Slide 18 - Curvas ROC e PR):
[NOTA: Assumindo que existe uma figura. Se n√£o, descreva verbalmente]

- Explicar Curva ROC: "Curva ROC mostra trade-off entre taxa de verdadeiros positivos (recall) e falsos positivos. Quanto mais pr√≥xima do canto superior esquerdo, melhor"
- Interpretar AUC-ROC: "AUC de 0.93 significa que, dado um par eleito-n√£o_eleito, modelo ranqueia corretamente em 93% dos casos - discrimina√ß√£o excepcional!"
- IMPORTANTE: Explicar Curva PR: "Curva Precision-Recall √© mais informativa para desbalanceamento - foca na classe rara. Linha horizontal (baseline) est√° em ~5.4% (preval√™ncia). Nossa curva muito acima disso mostra ganho real"
- Destacar bandas: "Bandas de confian√ßa via bootstrap (100 itera√ß√µes de reamostragem) mostram que performance √© est√°vel - n√£o √© sorte de uma amostra espec√≠fica"
- Mencionar ICs: "Intervalos de confian√ßa estreitos (¬±0.02 em AUC) indicam estimativas confi√°veis"
- Transi√ß√£o: "Mas quais features o modelo est√° usando? Vamos investigar"
- Tempo: ~2 minutos
-->

---

# Feature Importance

## Top 15 Features mais importantes

![width:800px](../../figures/feature_importance_top15.png)

<!--
NOTAS DO APRESENTADOR (Slide 19 - Feature Importance):
- Interpretar top 1: "Ocupa√ß√£o √© DISPARADO a feature mais importante -"
- Destacar top 3: "As tr√™s principais (ocupa√ß√£o, coliga√ß√£o, patrim√¥nio reelei√ß√£o)"
- CRUCIAL: Explicar reelei√ß√£o: "IS_REELEICAO" confirma a vantagem brutal da incumb√™ncia"
- Explicar UF_SP: "S√£o Paulo aparece isoladamente - col√©gio eleitoral gigante (70 vagas) cria din√¢mica pr√≥pria"
- IMPORTANTE: Conectar com target encoding: "Target encodings dominam porque capturam contexto hist√≥rico - n√£o apenas 'qual partido?', mas 'este partido historicamente elege?'"
- Mencionar feature engineering: "Valida√ß√£o do nosso trabalho de FE - features constru√≠das (encodings, logs, bin√°rios) dominam"
- Tempo: ~2,5 minutos
-->

---

# Interpretabilidade - SHAP

## SHAP (SHapley Additive exPlanations)

- **Abordagem te√≥rica de jogos** para explicar predi√ß√µes
- Mostra **impacto individual** de cada feature na predi√ß√£o
- Captura **intera√ß√µes** entre features

---

![width:500px](../../figures/shap_summary_plot.png)

<!--
NOTAS DO APRESENTADOR (Slide 20 - SHAP):
üìä Insights do Summary Plot:
  ‚Ä¢ Features no topo = maior impacto absoluto na predi√ß√£o
  ‚Ä¢ Padr√µes vermelho‚Üídireita ou azul‚Üíesquerda indicam correla√ß√£o positiva
  ‚Ä¢ Padr√µes invertidos indicam correla√ß√£o negativa
  ‚Ä¢ Dispers√£o grande = feature tem efeito vari√°vel entre candidatos

- Explicar SHAP brevemente: "SHAP vai al√©m de feature importance - mostra n√£o apenas 'o que importa' mas 'como importa' - dire√ß√£o e magnitude do efeito"
- Interpretar reelei√ß√£o: "Vejam o impacto dram√°tico: ser candidato √† reelei√ß√£o adiciona 15-20 pontos percentuais na probabilidade. √â o efeito mais forte isolado"
- IMPORTANTE: Explicar intera√ß√µes: "SHAP revela que patrim√¥nio e despesa t√™m efeito sin√©rgico - quando ambos s√£o altos simultaneamente, o boost √© maior que a soma dos efeitos individuais"
- Mencionar partido: "Partido grande tem efeito consistentemente positivo, mas a magnitude varia - um PT em SP tem impacto diferente de um PT em RO"
- Destacar UFs pequenas: "Estados com poucos candidatos (AC, RR) t√™m maior vari√¢ncia - modelo tem mais incerteza l√°. Faz sentido: menos dados hist√≥ricos"
- Conectar com EDA: "SHAP confirma quantitativamente o que vimos na an√°lise explorat√≥ria"
- Transi√ß√£o: "Agora vamos ver onde o modelo erra"
- Tempo: ~2 minutos
-->

---

# An√°lise de Erros - Matriz de Confus√£o

## Matriz Normalizada (% por linha)

|  | Predito: N√£o-Eleito | Predito: Eleito |
|---|---|---|
| **Real: N√£o-Eleito** | 96.2% (TN) | 1.8% (FP) |
| **Real: Eleito** | 42% (FN) | 58% (TP) |

---

## Tipos de erro

### Falsos Positivos (FP): 162 candidatos
- Preditos como eleitos mas **perderam**
- **Perfil**: Alto patrim√¥nio, partidos grandes, ocupa√ß√µes prestigiadas

### Falsos Negativos (FN): 215 candidatos
- **Eleitos** mas modelo previu derrota
- **Perfil**: Baixo patrim√¥nio, partidos pequenos, primeira candidatura, ocupa√ß√µes menos tradicionais

<!--
NOTAS DO APRESENTADOR (Slide 21 - An√°lise de Erros):
- Ler matriz: "Do total de n√£o-eleitos reais, identificamos corretamente 96.2% (TN). Dos eleitos reais, capturamos apenas 58% (TP)"
- IMPORTANTE: Explicar trade-off: "O modelo √© conservador - tem alta especificidade (96.2%) mas baixa sensibilidade (58%). Isso porque foi otimizado para F1, que equilibra precision e recall, mas penaliza FP mais que FN dado o desbalanceamento"
- Interpretar Falsos Positivos: "162 candidatos que 'pareciam' eleitos mas n√£o foram. T√≠pico: candidato rico de partido grande em UF competitiva. Modelo confia em estrutura, mas contexto local (advers√°rios fortes, polariza√ß√£o) determinou derrota"
- Interpretar Falsos Negativos: "215 candidatos que venceram 'apesar' do perfil. T√≠pico: candidato com carisma local, base fiel, ou beneficiado por voto √∫til. Features n√£o capturam popularidade ou campanha eficaz na m√≠dia"
- Mencionar limita√ß√µes: "Erros revelam vari√°veis ausentes: pesquisas eleitorais, engajamento em redes, esc√¢ndalos"
- Transi√ß√£o: "Vamos ver exemplos concretos"
- Tempo: ~2,5 minutos
-->

---

# Falsos Positivos - Exemplos

## Casos t√≠picos (preditos eleitos mas perderam)

**Candidato A**
- **Perfil**: Deputado, patrim√¥nio R$ 1.3M, UNI√ÉO, SP
- **Probabilidade predita**: 0.97 (alta confian√ßa)
- **Resultado**: N√£o eleito

<!--
NOTAS DO APRESENTADOR (Slide 22 - Falsos Positivos Exemplos):
- Contextualizar: "Vamos olhar casos concretos para entender onde o modelo se engana"
- Candidato A: "Modelo viu tudo a favor - patrim√¥nio alto, partido grande (UNI√ÉO), estado com muitas vagas (SP). Mas n√£o captou que UNI√ÉO em SP tem dezenas de candidatos competindo internamente - quociente alto mas distribui√ß√£o de votos dif√≠cil"
- IMPORTANTE: Explicar limita√ß√£o: "Modelo n√£o sabe quem s√£o os concorrentes espec√≠ficos, nem a for√ßa individual de cada candidato - trabalha com features agregadas"
- Destacar vari√°veis ausentes: "Esses erros apontam para vari√°veis cr√≠ticas n√£o dispon√≠veis: popularidade pr√©-campanha (pesquisas), men√ß√µes na m√≠dia, processos judiciais"
- Mencionar usabilidade: "Mesmo com FPs, o modelo √© √∫til - concentra aten√ß√£o em candidatos vi√°veis. An√°lise qualitativa complementa"
- Tempo: ~2 minutos
-->

---

# Falsos Negativos - Exemplos

## Casos t√≠picos (eleitos mas preditos como derrotados)

**Candidato B**
- **Perfil**: Policial Militar, patrim√¥nio R$ 19K, PODE, RJ
- **Probabilidade predita**: 0.03 (baixa confian√ßa)
- **Resultado**: Eleito

<!--
NOTAS DO APRESENTADOR (Slide 23 - Falsos Negativos Exemplos):
- Candidato B: "Modelo viu tudo contra - partido pequeno (PODE), baixo patrim√¥nio, sem incumb√™ncia. Probabilidade de 3% (muito improv√°vel)"
- IMPORTANTE: Explicar surpresa: "Mas ele venceu! Por qu√™? Provavelmente campanha eficaz em redes sociais (TikTok, Instagram), mobiliza√ß√£o de base progressista jovem. Modelo n√£o v√™ isso - n√£o temos features de engajamento digital"
- Destacar fen√¥meno: "Estes s√£o os 'outsiders' - candidatos que vencem pela for√ßa da campanha, n√£o da estrutura. Cada vez mais comuns na era das redes sociais"
- Candidato D: "M√©dico com patrim√¥nio moderado em estado pequeno (MS). Modelo subestimou, mas ele tinha capital social forte - apoio de prefeitos do interior, confian√ßa local"
- Explicar limita√ß√£o: "Modelo √© 'urbano-centrado' - captura bem din√¢mica de grandes centros, mas perde nuances de pol√≠tica interiorana"
- Mencionar melhoria: "Integra√ß√£o de dados de Twitter/Instagram reduziria FNs significativamente"
- Tempo: ~2 minutos
-->

---

# Conclus√µes

## Principais Achados

‚úÖ **Valida√ß√£o temporal bem-sucedida**: Generaliza√ß√£o 2018 ‚Üí 2022 (gap 4 anos)
‚úÖ **Random Forest vencedor**: F1=0.61, AUC-ROC=0.93, AUC-PR=0.56
‚úÖ **Features determinantes**: Partido/Coliga√ß√£o, incumb√™ncia, recursos financeiros

## Performance contextualizada

- Supera baselines significativamente (>30% em F1)
- Desbalanceamento 1:~15 superado com sucesso
- F1~0.61 demonstra **excelente capacidade preditiva** do modelo

<!--
NOTAS DO APRESENTADOR (Slide 24 - Conclus√µes Parte 1):
- Sintetizar conquistas: "Conseguimos construir um modelo robusto que generaliza entre ciclos eleitorais - isso √© dif√≠cil em dados pol√≠ticos porque contexto muda rapidamente"
- Contextualizar performance: "F1 de 0.61 √© um resultado excelente! Considerem: (1) Desbalanceamento severo; (2) Features limitadas a dados pr√©-campanha; (3) Vari√°veis n√£o-observadas (carisma, esc√¢ndalos) t√™m impacto enorme"
- IMPORTANTE: Destacar ganho relativo: "Superamos baseline simples em 36% e modelo aleat√≥rio em mais de 1000%. Em termos pr√°ticos, modelo identifica candidatos vi√°veis com alta precis√£o"
- Validar feature engineering: "Target encoding foi crucial - sozinho, partido representa 15% da import√¢ncia. Captura 'este partido historicamente elege?' de forma elegante"
- Mencionar Random Forest: "Random Forest venceu por capturar intera√ß√µes n√£o-lineares complexas e ser robusto a outliers. Ensemble de 300 √°rvores aprende padr√µes sutis"
- Preparar para limita√ß√µes: "Mas √© fundamental discutir o que N√ÉO conseguimos fazer"
- Tempo: ~2 minutos
-->

---

# ‚ö†Ô∏è Limita√ß√µes

## Dados Limitados
- Apenas **2 ciclos** eleitorais (2018, 2022)
- Imposs√≠vel analisar **tend√™ncias de longo prazo**
- Sens√≠vel a **eventos pontuais** (pandemia, impeachment)

## Vari√°veis Ausentes (cr√≠ticas)
- Popularidade pr√©-campanha (pesquisas de inten√ß√£o de voto)
- Engajamento em redes sociais (seguidores, likes)
- Cobertura da m√≠dia (men√ß√µes, debates)
- Esc√¢ndalos e processos judiciais

## Concept Drift
- Padr√µes eleitorais **mudam** entre ciclos
- Modelo precisa **re-treinamento** peri√≥dico
- N√£o garante performance em 2026+

<!--
NOTAS DO APRESENTADOR (Slide 25 - Limita√ß√µes):
- Ser transparente: "Todo modelo tem limita√ß√µes e √© nossa obriga√ß√£o como cientistas document√°-las claramente"
- Explicar dados: "TSE padronizou dados apenas a partir de 2018 - idealmente ter√≠amos 2014, 2010 para estimar degrada√ß√£o temporal de features"
- CRUCIAL: Destacar vari√°veis ausentes: "A limita√ß√£o mais s√©ria √© n√£o termos acesso a vari√°veis que sabemos serem importantes: popularidade antes da campanha, presen√ßa digital, cobertura da m√≠dia"
- Dar exemplo concreto: "Um candidato com 1 milh√£o de seguidores no Instagram tem vantagem clara, mas nosso modelo n√£o v√™ isso. Um candidato envolvido em esc√¢ndalo ter√° derrota, mas n√£o capturamos"
- Explicar concept drift: "Pol√≠tica muda r√°pido - partidos se fundem, polariza√ß√£o aumenta/diminui, novas m√≠dias emergem (TikTok). Modelo treinado em 2018 n√£o sabe nada sobre pandemia de 2020 que alterou din√¢mica de 2022"
- Mencionar re-treinamento: "Em produ√ß√£o real, modelo precisaria ser re-treinado a cada ciclo com dados mais recentes"
- Conectar com pr√≥ximo slide: "Mas isso tamb√©m abre caminho para trabalhos futuros"
- Tempo: ~2,5 minutos
-->

---

<!-- _class: lead -->

# Mensagem Final

## Este trabalho demonstra que:

Mesmo com **features limitadas** a dados declarat√≥rios pr√©-elei√ß√£o, √© poss√≠vel desenvolver **modelos preditivos robustos** que:

1. **Superam significativamente o acaso** (AUC-ROC 0.93 vs. 0.50)
2. **Identificam fatores estruturais** de sucesso eleitoral
3. **Generalizam entre ciclos** eleitorais (2018 ‚Üí 2022)

<!--
NOTAS DO APRESENTADOR (Slide 29 - Mensagem Final):
- Sintetizar positivos: "Demonstramos que √© vi√°vel construir modelos preditivos em contexto eleitoral brasileiro usando apenas dados p√∫blicos pr√©-campanha"
- IMPORTANTE: Contextualizar performance: "F1 de 0.61 e AUC de 0.93 s√£o resultados excelentes - demonstram que capturamos os principais padr√µes estruturais do sucesso eleitoral"
- Destacar valor cient√≠fico: "Contribui√ß√£o principal n√£o √© apenas o F1 absoluto, mas: (1) Framework metodol√≥gico reproduz√≠vel; (2) Identifica√ß√£o de features relevantes; (3) Documenta√ß√£o transparente de limita√ß√µes e vieses"
- Refor√ßar √©tica: "Mostramos que √© poss√≠vel E necess√°rio discutir implica√ß√µes √©ticas de forma estruturada - n√£o basta construir modelo, precisamos pensar no impacto social"
- Mencionar aplicabilidade: "Metodologia serve como ponto de partida para consultorias, pesquisadores e partidos - √© extens√≠vel e adapt√°vel"
- Encerrar com vis√£o: "Trabalho abre caminho para sistemas mais sofisticados integrando redes sociais, pesquisas e an√°lise causal"
- Tempo: ~1,5 minuto
-->

---

<!-- _class: lead -->
<!-- _paginate: false -->

# Obrigado! üôè

```
‚ÄúO modelo n√£o √© o fim ‚Äî √© o come√ßo da decis√£o.‚Äù
```

## Perguntas?

**Contato**
Artur Garcia & Artur Saraiva
Universidade Federal do Cear√° (UFC)

<!--
NOTAS DO APRESENTADOR (Slide 30 - Encerramento):
- Agradecer: "Agrade√ßo a aten√ß√£o de todos. Foi um prazer apresentar este trabalho"
- Abrir para perguntas: "Estou √† disposi√ß√£o para perguntas e discuss√µes"
- Preparar-se para poss√≠veis perguntas:
  1. "Por que n√£o testou modelo X?" ‚Üí Responder com screening inicial que testou 4 arquiteturas, Random Forest venceu
  2. "F1 de 0.61 n√£o poderia ser melhor?" ‚Üí Contextualizar que j√° √© excelente considerando desbalanceamento, destacar AUC-ROC de 0.93
  3. "Como lidar com concept drift?" ‚Üí Mencionar re-treinamento peri√≥dico, monitoramento de performance
  4. "E vi√©s de g√™nero?" ‚Üí Reconhecer que n√£o fizemos an√°lise aprofundada, citar como trabalho futuro priorit√°rio
  5. "Modelo pode ser usado em produ√ß√£o?" ‚Üí Sim, mas com caveats: n√£o substitui an√°lise humana, precisa re-treino, considerar √©tica
- Agradecer novamente ao final
- Tempo: vari√°vel conforme perguntas
-->
